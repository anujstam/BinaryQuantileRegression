{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8cvMyCsw-q0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "EHOi2Xj-xspY",
    "outputId": "e17809e3-6b4c-4482-c55a-5b09d8133b38"
   },
   "outputs": [],
   "source": [
    "# Generate Dataloaders\n",
    "\n",
    "np.random.seed(321)\n",
    "train_dir = 'train'\n",
    "train_files = os.listdir(train_dir)\n",
    "all_dogs = []\n",
    "all_cats = []\n",
    "for i in train_files:\n",
    "    if('dog' in i):\n",
    "        all_dogs.append('train/' + i)\n",
    "    elif('cat' in i):\n",
    "        all_cats.append('train/' + i)\n",
    "ind_dog = []\n",
    "ind_cat = []\n",
    "names_dog_test = []\n",
    "names_cat_test = []\n",
    "\n",
    "for i in range(4000):\n",
    "    r = np.random.randint(0,12500)\n",
    "    if r not in ind_dog: \n",
    "        ind_dog.append(r)\n",
    "    if(len(np.unique(np.array(ind_dog))) == 2500):\n",
    "        break\n",
    "\n",
    "for i in range(4000):\n",
    "    r = np.random.randint(0,12500)\n",
    "    if r not in ind_cat: \n",
    "        ind_cat.append(r)\n",
    "    if(len(np.unique(np.array(ind_cat))) == 2500):\n",
    "        break\n",
    "        \n",
    "for i in ind_dog:\n",
    "    names_dog_test.append(all_dogs[i])\n",
    "for i in ind_cat:\n",
    "    names_cat_test.append(all_cats[i])\n",
    "    \n",
    "names_dog_train  = []\n",
    "names_cat_train = []\n",
    "cc = 0\n",
    "for i in range(12500):\n",
    "    if(i in ind_dog):\n",
    "        cc = cc + 1\n",
    "        continue\n",
    "    else:\n",
    "        names_dog_train.append(all_dogs[i])\n",
    "\n",
    "        cc = 0\n",
    "for i in range(12500):\n",
    "    if(i in ind_cat):\n",
    "        cc = cc + 1\n",
    "        continue\n",
    "    else:\n",
    "        names_cat_train.append(all_cats[i])\n",
    "\n",
    "all_train_ids = np.concatenate((names_dog_train,names_cat_train))\n",
    "all_test_ids = np.concatenate((names_dog_test,names_cat_test))\n",
    "all_train_ids.shape,all_test_ids.shape\n",
    "all_train_labels = np.concatenate((np.zeros((10000,1)),np.ones((10000,1))))\n",
    "all_test_labels = np.concatenate((np.zeros((2500,1)),np.ones((2500,1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x90Nmsy0xuEw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "def my_transform(key):\n",
    "    train_sequence = [\n",
    "                      transforms.Resize((224,224)),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.ToTensor()]\n",
    "    test_sequence = [transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor()]\n",
    "    data_transforms = {'train': transforms.Compose(train_sequence),\n",
    "                       'test': transforms.Compose(test_sequence)}\n",
    "    return data_transforms[key]\n",
    "\n",
    "class CatsandDogs(Dataset):\n",
    "    def __init__(self,path_is,targets,transform):\n",
    "        self.path_is = path_is\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_is)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.path_is[idx]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = np.int(self.targets[idx])\n",
    "        return image,target\n",
    "\n",
    "dats_train = CatsandDogs(all_train_ids,all_train_labels,transform=my_transform(key=\"train\"))\n",
    "dats_test = CatsandDogs(all_test_ids,all_test_labels,transform=my_transform(key=\"test\"))\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dats_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(dats_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Torch Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anLan5O2x3SA"
   },
   "outputs": [],
   "source": [
    "def cumLaplaceDistribution(y_pred,mean,standard_deviation,all_qs):\n",
    "    term1 = ((1-all_qs) * (y_pred - mean))/standard_deviation\n",
    "    term1.clamp_(max = 0)\n",
    "    lesser_term = all_qs * torch.exp(term1)\n",
    "    term2 = (-1.0 * all_qs * (y_pred - mean))/standard_deviation\n",
    "    term2.clamp_(max = 0)\n",
    "    greater_term = 1 - ((1-all_qs) * torch.exp(term2))\n",
    "    dummy_ones = torch.ones_like(mean)\n",
    "    y_dummy_pred = torch.div(y_pred,dummy_ones)\n",
    "    y_dummy_pred[y_pred >= mean] = 1.0\n",
    "    y_dummy_pred[y_pred < mean] = 0.0\n",
    "    return ((1 - y_dummy_pred) * lesser_term )+  (y_dummy_pred * greater_term)\n",
    "\n",
    "\n",
    "def logLikelihoodLoss(y_true,y_pred,mean,standard_deviation,all_qs):\n",
    "    new_pred = y_pred\n",
    "    prob_tens = cumLaplaceDistribution(0.0,mean = new_pred,standard_deviation = standard_deviation,all_qs = all_qs)\n",
    "    prob_tens.clamp_(min = 1e-7,max = 1 - 1e-7)\n",
    "    if_one = y_true * torch.log(1 - prob_tens)\n",
    "    if_zero = (1 - y_true) * torch.log(prob_tens)\n",
    "    result = - 1 * torch.mean(if_one + if_zero)\n",
    "    return result\n",
    "\n",
    "def customLoss(y_true, y_pred, mean, standard_deviation, all_qs, penalty):\n",
    "    ind_losses = []\n",
    "    for i,j in enumerate(all_qs):\n",
    "        solo_loss = logLikelihoodLoss(y_true[:,0],y_pred[:,i] ,mean, standard_deviation, j)\n",
    "        ind_losses.append(solo_loss)\n",
    "    zero = torch.Tensor([0]).to(device)\n",
    "    dummy1 = y_pred[:,1:] - y_pred[:,:-1]\n",
    "    dummy2 = penalty * torch.mean(torch.max(zero,-1.0 * dummy1))\n",
    "    total_loss  = torch.mean(torch.stack(ind_losses)) +dummy2\n",
    "    return total_loss\n",
    "\n",
    "def customTestPred(y_pred,mean,standard_deviation,all_qs,batch_size = 1):\n",
    "    if(batch_size == 1):\n",
    "        acc = []\n",
    "        cdfs = []\n",
    "        eps = 1e-10\n",
    "        val = (y_pred - mean)/standard_deviation \n",
    "        for xx in range(batch_size):\n",
    "            if(y_pred < mean.item()):\n",
    "                lesser_term = all_qs * torch.exp((1 - all_qs) * val.item())\n",
    "                lesser_term  = 1 - lesser_term\n",
    "                cdfs.append(lesser_term.item())\n",
    "                if(lesser_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "            \n",
    "            elif(y_pred >= mean.item()):\n",
    "                greater_term = 1 - ((1-all_qs) * torch.exp(-1 * all_qs * val.item()))\n",
    "                greater_term = 1 - greater_term\n",
    "                cdfs.append(greater_term.item())\n",
    "                if(greater_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "    \n",
    "    elif(batch_size > 1):\n",
    "        acc = []\n",
    "        cdfs = []\n",
    "        eps = 1e-10\n",
    "        val = (y_pred - mean)/standard_deviation \n",
    "        for xx in range(batch_size):\n",
    "            if(y_pred < mean[xx]):\n",
    "                lesser_term = all_qs * torch.exp((1 - all_qs) * val[xx])\n",
    "                lesser_term  = 1 - lesser_term\n",
    "                cdfs.append(lesser_term.item())\n",
    "                if(lesser_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "            elif(y_pred >= mean[xx]):\n",
    "                greater_term = 1 - ((1-all_qs) * torch.exp(-1 * all_qs * val[xx]))\n",
    "                greater_term = 1 - greater_term\n",
    "                cdfs.append(greater_term.item())\n",
    "                if(greater_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "    return torch.Tensor(acc).to(device).reshape(-1,1),torch.Tensor(cdfs).to(device).reshape(-1,1)\n",
    "\n",
    "def acc_Q(train_preds,train_labels):\n",
    "    train_preds = np.array(train_preds).reshape(-1,1)\n",
    "    train_labels = np.array(train_labels).reshape(-1,1)\n",
    "\n",
    "    cdfs_acc,_ = customTestPred(0,train_preds,standard_deviation = 1,all_qs = torch.Tensor([0.5]),\n",
    "                                batch_size = train_preds.shape[0])\n",
    "\n",
    "    count = 0\n",
    "    for i,j in zip(cdfs_acc,train_labels):\n",
    "        if(i.item() == j[0]):\n",
    "            count += 1\n",
    "    return count/train_labels.shape[0]\n",
    "\n",
    "def acc_tests(test_preds,test_labels):\n",
    "    test_preds = np.array(test_preds).reshape(-1,1)\n",
    "    test_labels = np.array(test_labels).reshape(-1,1)\n",
    "    cdfs_acc,_ = customTestPred(0,test_preds,standard_deviation = 1,all_qs = torch.Tensor([0.5]),\n",
    "                                batch_size = test_preds.shape[0])\n",
    "\n",
    "    count = 0\n",
    "    for i,j in zip(cdfs_acc,test_labels):\n",
    "        if(i.item() == j[0]):\n",
    "            count += 1\n",
    "    return count/test_labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HqCmJ8Nf8Hk"
   },
   "outputs": [],
   "source": [
    "def lr_schedule_combined_sgd(model, loader, batch_size):\n",
    "    Kz = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(loader):\n",
    "            inputs,labels = j[0],j[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            op = model.conv1(inputs)\n",
    "            op = model.bn1(op)\n",
    "            op = model.relu(op)\n",
    "            op = model.maxpool(op)\n",
    "            op = model.layer1(op)\n",
    "            op = model.layer2(op)\n",
    "            op = model.layer3(op)\n",
    "            op = model.layer4(op)\n",
    "            op = model.avgpool(op)\n",
    "            op = op.reshape(labels.shape[0], 512)\n",
    "            for i in range(len(model.fc)-2):\n",
    "                op = model.fc[i](op)\n",
    "            activ = np.linalg.norm(op.detach().cpu().numpy())\n",
    "            if activ > Kz:\n",
    "                Kz = activ\n",
    "    factor = 1\n",
    "    K_ = (factor * Kz) / (batch_size)\n",
    "    lr = 1 / K_\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jItat7f6yEHv"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "\n",
    "def train_adaptive_lr(model,loader,optimizer):\n",
    "    train_preds_Q = []\n",
    "    train_preds_bce = []\n",
    "    train_labels = []\n",
    "    lr_val = lr_schedule_combined_sgd(model, loader, batch_size=128)\n",
    "    optimizer.param_groups[0]['lr'] = lr_val\n",
    "    model.train()\n",
    "    for i,j in enumerate(loader):\n",
    "        inputs,labels = j[0],j[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.shape\n",
    "        optimizer.zero_grad()\n",
    "        op_qs = model(inputs)\n",
    "        lossQ = customLoss(labels.reshape(-1,1),op_qs, mean_is,std_is,all_qs,penalty)\n",
    "        lossQ.backward()\n",
    "        optimizer.step()\n",
    "        for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "            train_preds_Q.append(lag.item())\n",
    "        for lag in labels.reshape(-1,1):\n",
    "            train_labels.append(lag.item())\n",
    "\n",
    "    acc_is_Q = acc_Q(train_preds_Q,train_labels)\n",
    "    print(\"Train Acc Q : %f \"%(acc_is_Q))\n",
    "    return acc_is_Q\n",
    "\n",
    "\n",
    "def train_fixed(model,loader,optimizer):\n",
    "    train_preds_Q = []\n",
    "    train_preds_bce = []\n",
    "    train_labels = []\n",
    "    model.train()\n",
    "    for i,j in enumerate(loader):\n",
    "        inputs,labels = j[0],j[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.shape\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        op_qs = model(inputs)\n",
    "        lossQ = customLoss(labels.reshape(-1,1),op_qs, mean_is,std_is,all_qs,penalty)\n",
    "        lossQ.backward()\n",
    "        optimizer.step()\n",
    "        for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "            train_preds_Q.append(lag.item())\n",
    "        for lag in labels.reshape(-1,1):\n",
    "            train_labels.append(lag.item())\n",
    "    \n",
    "    acc_is_Q = acc_Q(train_preds_Q,train_labels)\n",
    "    print(\"Train Acc Q : %f \"%(acc_is_Q))\n",
    "    return acc_is_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7duarjXOyFzR"
   },
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    model.eval()\n",
    "    test_preds_Q = []\n",
    "    test_preds_bce = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(loader):\n",
    "            inputs,labels = j[0],j[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            op_qs = model(inputs)\n",
    "            for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "                test_preds_Q.append(lag.item())\n",
    "            for lag in labels.reshape(-1,1):\n",
    "                test_labels.append(lag.item())\n",
    "    acc_is_Q = acc_tests(test_preds_Q,test_labels)\n",
    "    print(\"Test Acc Q : %f  \"%(acc_is_Q))\n",
    "    return acc_is_Q\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUhah-qdxwFQ"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(756)\n",
    "model_1 = torchvision.models.resnet18(pretrained=False)\n",
    "model_1.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_features = model_1.fc.in_features\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "lr_is = 1e-2\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = lr_is)\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "epsilon = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Dj5-x5olHtK"
   },
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "\n",
    "target_acc = 0.90\n",
    "fixed_acc = 0\n",
    "fixed_epochs = 0\n",
    "fixed_epoch_val =0\n",
    "adaptive_acc = 0\n",
    "adaptive_epochs = 0\n",
    "\n",
    "adaptive_time = []\n",
    "fixed_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7la2_m2RyHY_",
    "outputId": "84eb990f-3c40-4412-8d14-af8d6be14997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fixed LR Results\n",
      "Fixed Iteration: 1\n",
      "Train Acc Q : 0.567650 \n",
      "Test Acc Q : 0.616600  \n",
      "Fixed Iteration: 2\n",
      "Train Acc Q : 0.624400 \n",
      "Test Acc Q : 0.546400  \n",
      "Fixed Iteration: 3\n",
      "Train Acc Q : 0.643650 \n",
      "Test Acc Q : 0.639400  \n",
      "Fixed Iteration: 4\n",
      "Train Acc Q : 0.667400 \n",
      "Test Acc Q : 0.632400  \n",
      "Fixed Iteration: 5\n",
      "Train Acc Q : 0.692250 \n",
      "Test Acc Q : 0.583200  \n",
      "Fixed Iteration: 6\n",
      "Train Acc Q : 0.718900 \n",
      "Test Acc Q : 0.664200  \n",
      "Fixed Iteration: 7\n",
      "Train Acc Q : 0.739550 \n",
      "Test Acc Q : 0.551200  \n",
      "Fixed Iteration: 8\n",
      "Train Acc Q : 0.759200 \n",
      "Test Acc Q : 0.663400  \n",
      "Fixed Iteration: 9\n",
      "Train Acc Q : 0.770250 \n",
      "Test Acc Q : 0.733000  \n",
      "Fixed Iteration: 10\n",
      "Train Acc Q : 0.784250 \n",
      "Test Acc Q : 0.730600  \n",
      "Fixed Iteration: 11\n",
      "Train Acc Q : 0.793550 \n",
      "Test Acc Q : 0.730000  \n",
      "Fixed Iteration: 12\n",
      "Train Acc Q : 0.813550 \n",
      "Test Acc Q : 0.687200  \n",
      "Fixed Iteration: 13\n",
      "Train Acc Q : 0.819800 \n",
      "Test Acc Q : 0.579200  \n",
      "Fixed Iteration: 14\n",
      "Train Acc Q : 0.831250 \n",
      "Test Acc Q : 0.742800  \n",
      "Fixed Iteration: 15\n",
      "Train Acc Q : 0.843550 \n",
      "Test Acc Q : 0.600000  \n",
      "Fixed Iteration: 16\n",
      "Train Acc Q : 0.854400 \n",
      "Test Acc Q : 0.614200  \n",
      "Fixed Iteration: 17\n",
      "Train Acc Q : 0.864150 \n",
      "Test Acc Q : 0.622800  \n",
      "Fixed Iteration: 18\n",
      "Train Acc Q : 0.868400 \n",
      "Test Acc Q : 0.515800  \n",
      "Fixed Iteration: 19\n",
      "Train Acc Q : 0.880150 \n",
      "Test Acc Q : 0.741600  \n",
      "Fixed Iteration: 20\n",
      "Train Acc Q : 0.886000 \n",
      "Test Acc Q : 0.586800  \n",
      "Acc:0.74 at epoch 14 at 2.84 min per epoch\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Fixed LR Results\")\n",
    "for iter in range(max_epochs):\n",
    "    fixed_epochs +=1\n",
    "    print(\"Fixed Iteration:\", fixed_epochs)\n",
    "    start = time.time()\n",
    "    fixed_acc_train = train_fixed(model_1,train_dataloader,optimizer)\n",
    "    end = time.time()\n",
    "    fixed_time.append(end-start)\n",
    "    fixed_acc_test = test(model_1,test_dataloader)\n",
    "    if fixed_acc_test > fixed_acc and fixed_acc_train>fixed_acc:\n",
    "        fixed_acc = fixed_acc_test\n",
    "        fixed_epoch_val = fixed_epochs\n",
    "\n",
    "print(\"Acc:{:.2f} at epoch {} at {:.2f} min per epoch\".format(fixed_acc,fixed_epoch_val,np.mean(fixed_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(756)\n",
    "model_1 = torchvision.models.resnet18(pretrained=False)\n",
    "model_1.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_features = model_1.fc.in_features\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "lr_is = 1e-2\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = lr_is)\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "epsilon = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_Yz03i56x6FL",
    "outputId": "a9b7afd2-9d6b-494b-9d3a-49de85a2cdb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Iteration: 1\n",
      "Train Acc Q : 0.586850 \n",
      "Train Time: 241.387\n",
      "Test Acc Q : 0.509000  \n",
      "Adaptive Iteration: 2\n",
      "Train Acc Q : 0.700300 \n",
      "Train Time: 289.132\n",
      "Test Acc Q : 0.507600  \n",
      "Adaptive Iteration: 3\n",
      "Train Acc Q : 0.754850 \n",
      "Train Time: 289.372\n",
      "Test Acc Q : 0.639600  \n",
      "Adaptive Iteration: 4\n",
      "Train Acc Q : 0.798850 \n",
      "Train Time: 288.841\n",
      "Test Acc Q : 0.665200  \n",
      "Adaptive Iteration: 5\n",
      "Train Acc Q : 0.816650 \n",
      "Train Time: 289.230\n",
      "Test Acc Q : 0.661600  \n",
      "Adaptive Iteration: 6\n",
      "Train Acc Q : 0.815200 \n",
      "Train Time: 288.760\n",
      "Test Acc Q : 0.717400  \n",
      "Adaptive Iteration: 7\n",
      "Train Acc Q : 0.879100 \n",
      "Train Time: 289.538\n",
      "Test Acc Q : 0.769600  \n",
      "\n",
      "Acc:0.77 at epoch 7 at 4.71 min per epoch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_epochs):\n",
    "    adaptive_epochs +=1\n",
    "    print(\"Adaptive Iteration:\", adaptive_epochs)\n",
    "    start = time.time()\n",
    "    adaptive_acc_train = train_adaptive_lr(model_1,train_dataloader,optimizer)\n",
    "    end = time.time()\n",
    "    print(\"Train Time: {:.3f}\".format(end-start))\n",
    "    adaptive_time.append(end-start)\n",
    "    adaptive_acc_test = test(model_1,test_dataloader)\n",
    "    if adaptive_acc_test > fixed_acc and adaptive_acc_train>fixed_acc:\n",
    "        print()\n",
    "        print(\"Acc:{:.2f} at epoch {} at {:.2f} min per epoch\".format(adaptive_acc_test,adaptive_epochs,\n",
    "                                                                      np.mean(adaptive_time)/60))\n",
    "        break\n",
    "\n",
    "\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DvC_AdaptiveLR_Resnet18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
