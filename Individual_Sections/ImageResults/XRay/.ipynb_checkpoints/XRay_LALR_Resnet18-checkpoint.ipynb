{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8cvMyCsw-q0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-ujoKRaqxqHk",
    "outputId": "d1ebd024-5f73-4a7b-f216-40d4051e8053"
   },
   "outputs": [],
   "source": [
    "# To extract the zip file. Can be skipped if already extracted\n",
    "\n",
    "needs_extract = False\n",
    "if needs_extract:\n",
    "    local_zip = 'chest-xray-pneumonia.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('demo')\n",
    "    zip_ref.close()\n",
    "    base_path = \"demo/chest_xray/test\"\n",
    "    folder = os.listdir(base_path)\n",
    "    !rm -r 'demo/chest_xray/chest_xray/'\n",
    "    !rm -r 'demo/chest_xray/__MACOSX'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lQ0QZ683dYrz",
    "outputId": "31442d1f-7ef2-4f24-f43c-f983b670f54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Train Images  1341\n",
      "Pneumonia Train Images  3875\n"
     ]
    }
   ],
   "source": [
    "train_normal_path = 'demo/chest_xray/train/NORMAL/'\n",
    "folder = os.listdir(train_normal_path)\n",
    "print(\"Normal Train Images \", len(folder))\n",
    "total_images = len(folder)\n",
    "df_normal_train =  pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n",
    "for i in range(total_images):\n",
    "    df_normal_train.iloc[i]['path'] =train_normal_path + folder[i]\n",
    "    df_normal_train.iloc[i]['target'] = 0\n",
    "train_pne_path = 'demo/chest_xray/train/PNEUMONIA/'\n",
    "folder = os.listdir(train_pne_path)\n",
    "print(\"Pneumonia Train Images \", len(folder))\n",
    "\n",
    "total_images =  len(folder)\n",
    "df_pne_train =  pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n",
    "for i in range(total_images):\n",
    "    df_pne_train.iloc[i]['path'] = train_pne_path+ folder[i]\n",
    "    df_pne_train.iloc[i]['target'] = 1\n",
    "\n",
    "RAND_STATE = 4545\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5Z6CajGOdeEf",
    "outputId": "a15b6d32-e99f-4413-d097-62a1195b113a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Test Images  234\n",
      "Pneumonia Test Images  390\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "df_train = pd.concat([df_normal_train.copy(),df_pne_train.copy()])\n",
    "df_train = df_train.sample(frac = 1,random_state = RAND_STATE)\n",
    "test_normal_path = 'demo/chest_xray/test/NORMAL/'\n",
    "folder = os.listdir(test_normal_path)\n",
    "print(\"Normal Test Images \", len(folder))\n",
    "total_images = len(folder)\n",
    "df_normal_test =  pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n",
    "for i in range(total_images):\n",
    "    df_normal_test.iloc[i]['path'] =test_normal_path + folder[i]\n",
    "    df_normal_test.iloc[i]['target'] = 0\n",
    "test_pne_path = 'demo/chest_xray/test/PNEUMONIA/'\n",
    "folder = os.listdir(test_pne_path)\n",
    "print(\"Pneumonia Test Images \", len(folder))\n",
    "total_images = len(folder)\n",
    "df_pne_test =  pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n",
    "for i in range(total_images):\n",
    "    df_pne_test.iloc[i]['path'] =test_pne_path + folder[i]\n",
    "    df_pne_test.iloc[i]['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHOi2Xj-xspY"
   },
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_normal_test.copy(),df_pne_test.copy()])\n",
    "df_test = df_test.sample(frac = 1,random_state = RAND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x90Nmsy0xuEw"
   },
   "outputs": [],
   "source": [
    "def my_transform(key=\"train\"):\n",
    "    train_sequence = [transforms.Resize((224,224)),                      \n",
    "                      transforms.ToTensor()]\n",
    "    test_sequence = [transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor()]\n",
    "    data_transforms = {'train': transforms.Compose(train_sequence),\n",
    "                       'test': transforms.Compose(test_sequence)}\n",
    "    return data_transforms[key]\n",
    "\n",
    "\n",
    "class PNEDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.states = df\n",
    "        self.transform=transform\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.states.path.values[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "         \n",
    "        target = np.int(self.states.target.values[idx])\n",
    "        return image,target\n",
    "\n",
    "train_dataset = PNEDataset(df_train, transform=my_transform(key=\"train\"))\n",
    "test_dataset =  PNEDataset(df_test, transform=my_transform(key=\"test\"))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anLan5O2x3SA"
   },
   "outputs": [],
   "source": [
    "def cumLaplaceDistribution(y_pred,mean,standard_deviation,all_qs):\n",
    "    term1 = ((1-all_qs) * (y_pred - mean))/standard_deviation\n",
    "    term1.clamp_(max = 0)\n",
    "    lesser_term = all_qs * torch.exp(term1)\n",
    "    term2 = (-1.0 * all_qs * (y_pred - mean))/standard_deviation\n",
    "    term2.clamp_(max = 0)\n",
    "    greater_term = 1 - ((1-all_qs) * torch.exp(term2))\n",
    "    dummy_ones = torch.ones_like(mean)\n",
    "    y_dummy_pred = torch.div(y_pred,dummy_ones)\n",
    "    y_dummy_pred[y_pred >= mean] = 1.0\n",
    "    y_dummy_pred[y_pred < mean] = 0.0\n",
    "    return ((1 - y_dummy_pred) * lesser_term )+  (y_dummy_pred * greater_term)\n",
    "\n",
    "\n",
    "def logLikelihoodLoss(y_true,y_pred,mean,standard_deviation,all_qs):\n",
    "    new_pred = y_pred\n",
    "    prob_tens = cumLaplaceDistribution(0.0,mean = new_pred,standard_deviation = standard_deviation,all_qs = all_qs)\n",
    "    prob_tens.clamp_(min = 1e-7,max = 1 - 1e-7)\n",
    "    if_one = y_true * torch.log(1 - prob_tens)\n",
    "    if_zero = (1 - y_true) * torch.log(prob_tens)\n",
    "    result = - 1 * torch.mean(if_one + if_zero)\n",
    "    return result\n",
    "\n",
    "def customLoss(y_true, y_pred, mean, standard_deviation, all_qs, penalty):\n",
    "    ind_losses = []\n",
    "    for i,j in enumerate(all_qs):\n",
    "        solo_loss = logLikelihoodLoss(y_true[:,0],y_pred[:,i] ,mean, standard_deviation, j)\n",
    "        ind_losses.append(solo_loss)\n",
    "    zero = torch.Tensor([0]).to(device)\n",
    "    dummy1 = y_pred[:,1:] - y_pred[:,:-1]\n",
    "    dummy2 = penalty * torch.mean(torch.max(zero,-1.0 * dummy1))\n",
    "    total_loss  = torch.mean(torch.stack(ind_losses)) +dummy2\n",
    "    return total_loss\n",
    "\n",
    "def customTestPred(y_pred,mean,standard_deviation,all_qs,batch_size = 1):\n",
    "    if(batch_size == 1):\n",
    "        acc = []\n",
    "        cdfs = []\n",
    "        eps = 1e-10\n",
    "        val = (y_pred - mean)/standard_deviation \n",
    "        for xx in range(batch_size):\n",
    "            if(y_pred < mean.item()):\n",
    "                lesser_term = all_qs * torch.exp((1 - all_qs) * val.item())\n",
    "                lesser_term  = 1 - lesser_term\n",
    "                cdfs.append(lesser_term.item())\n",
    "                if(lesser_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "            \n",
    "            elif(y_pred >= mean.item()):\n",
    "                greater_term = 1 - ((1-all_qs) * torch.exp(-1 * all_qs * val.item()))\n",
    "                greater_term = 1 - greater_term\n",
    "                cdfs.append(greater_term.item())\n",
    "                if(greater_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "    \n",
    "    elif(batch_size > 1):\n",
    "        acc = []\n",
    "        cdfs = []\n",
    "        eps = 1e-10\n",
    "        val = (y_pred - mean)/standard_deviation \n",
    "        for xx in range(batch_size):\n",
    "            if(y_pred < mean[xx]):\n",
    "                lesser_term = all_qs * torch.exp((1 - all_qs) * val[xx])\n",
    "                lesser_term  = 1 - lesser_term\n",
    "                cdfs.append(lesser_term.item())\n",
    "                if(lesser_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "            elif(y_pred >= mean[xx]):\n",
    "                greater_term = 1 - ((1-all_qs) * torch.exp(-1 * all_qs * val[xx]))\n",
    "                greater_term = 1 - greater_term\n",
    "                cdfs.append(greater_term.item())\n",
    "                if(greater_term.item() >= 0.5):\n",
    "                    acc.append([1])\n",
    "                else:\n",
    "                    acc.append([0])\n",
    "    return torch.Tensor(acc).to(device).reshape(-1,1),torch.Tensor(cdfs).to(device).reshape(-1,1)\n",
    "\n",
    "def acc_Q(train_preds,train_labels):\n",
    "    train_preds = np.array(train_preds).reshape(-1,1)\n",
    "    train_labels = np.array(train_labels).reshape(-1,1)\n",
    "\n",
    "    cdfs_acc,_ = customTestPred(0,train_preds,standard_deviation = 1,all_qs = torch.Tensor([0.5]),\n",
    "                                batch_size = train_preds.shape[0])\n",
    "\n",
    "    count = 0\n",
    "    for i,j in zip(cdfs_acc,train_labels):\n",
    "        if(i.item() == j[0]):\n",
    "            count += 1\n",
    "    return count/train_labels.shape[0]\n",
    "\n",
    "def acc_tests(test_preds,test_labels):\n",
    "    test_preds = np.array(test_preds).reshape(-1,1)\n",
    "    test_labels = np.array(test_labels).reshape(-1,1)\n",
    "    cdfs_acc,_ = customTestPred(0,test_preds,standard_deviation = 1,all_qs = torch.Tensor([0.5]),\n",
    "                                batch_size = test_preds.shape[0])\n",
    "\n",
    "    count = 0\n",
    "    for i,j in zip(cdfs_acc,test_labels):\n",
    "        if(i.item() == j[0]):\n",
    "            count += 1\n",
    "    return count/test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HqCmJ8Nf8Hk"
   },
   "outputs": [],
   "source": [
    "def lr_schedule_combined_sgd(model, loader, batch_size):\n",
    "    Kz = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(loader):\n",
    "            inputs,labels = j[0],j[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            op = model.conv1(inputs)\n",
    "            op = model.bn1(op)\n",
    "            op = model.relu(op)\n",
    "            op = model.maxpool(op)\n",
    "            op = model.layer1(op)\n",
    "            op = model.layer2(op)\n",
    "            op = model.layer3(op)\n",
    "            op = model.layer4(op)\n",
    "            op = model.avgpool(op)\n",
    "            op = torch.flatten(op,1)\n",
    "            for i in range(len(model.fc)-1):\n",
    "                op = model.fc[i](op)\n",
    "            \n",
    "            activ = np.linalg.norm(op.detach().cpu().numpy())\n",
    "            if activ > Kz:\n",
    "                Kz = activ\n",
    "    factor = 1\n",
    "    K_ = (factor * Kz) / (batch_size)\n",
    "    lr = 1 / K_\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jItat7f6yEHv"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def train_adaptive_lr(model,loader,optimizer):\n",
    "    train_preds_Q = []\n",
    "    train_preds_bce = []\n",
    "    train_labels = []\n",
    "    lr_val = lr_schedule_combined_sgd(model, loader, batch_size=32)\n",
    "    optimizer.param_groups[0]['lr'] = lr_val\n",
    "    model.train()\n",
    "    for i,j in enumerate(loader):\n",
    "        inputs,labels = j[0],j[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.shape\n",
    "        optimizer.zero_grad()\n",
    "        op_qs = model(inputs)\n",
    "        lossQ = customLoss(labels.reshape(-1,1),op_qs, mean_is,std_is,all_qs,penalty)\n",
    "        lossQ.backward()\n",
    "        optimizer.step()\n",
    "        for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "            train_preds_Q.append(lag.item())\n",
    "        for lag in labels.reshape(-1,1):\n",
    "            train_labels.append(lag.item())\n",
    "    acc_is_Q = acc_Q(train_preds_Q,train_labels)\n",
    "    print(\"Train Acc Q : %f \"%(acc_is_Q))\n",
    "    return acc_is_Q\n",
    "\n",
    "\n",
    "def train_fixed(model,loader,optimizer):\n",
    "    train_preds_Q = []\n",
    "    train_preds_bce = []\n",
    "    train_labels = []\n",
    "    model.train()\n",
    "    for i,j in enumerate(loader):\n",
    "        inputs,labels = j[0],j[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.shape\n",
    "        optimizer.zero_grad()\n",
    "        op_qs = model(inputs)\n",
    "        lossQ = customLoss(labels.reshape(-1,1),op_qs, mean_is,std_is,all_qs,penalty)\n",
    "        lossQ.backward()\n",
    "        optimizer.step()\n",
    "        for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "            train_preds_Q.append(lag.item())\n",
    "        for lag in labels.reshape(-1,1):\n",
    "            train_labels.append(lag.item())\n",
    "    \n",
    "    acc_is_Q = acc_Q(train_preds_Q,train_labels)\n",
    "    print(\"Train Acc Q : %f \"%(acc_is_Q))\n",
    "    return acc_is_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7duarjXOyFzR"
   },
   "outputs": [],
   "source": [
    "def test(model,loader,verbose=True):\n",
    "    model.eval()\n",
    "    test_preds_Q = []\n",
    "    test_preds_bce = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(loader):\n",
    "            inputs,labels = j[0],j[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            op_qs = model(inputs)\n",
    "            for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "                test_preds_Q.append(lag.item())\n",
    "            for lag in labels.reshape(-1,1):\n",
    "                test_labels.append(lag.item())\n",
    "                \n",
    "    acc_is_Q = acc_tests(test_preds_Q,test_labels)\n",
    "    if verbose:\n",
    "        print(\"Test Acc Q : %f  \"%(acc_is_Q))\n",
    "    return acc_is_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUhah-qdxwFQ"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(756)\n",
    "model_1 = torchvision.models.resnet18(pretrained=False)\n",
    "model_1.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_features = model_1.fc.in_features\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "\n",
    "'''\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "'''\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "lr_is = 1e-2\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = lr_is)\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "epsilon = 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7la2_m2RyHY_",
    "outputId": "1d46b577-0d5f-43f3-eba8-1b7f4660b58b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR=0.01\n",
      "Establishing Fixed LR Best results\n",
      "Fixed Iteration: 1\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.806\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 2\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.184\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 3\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.372\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 4\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.287\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 5\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.074\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 6\n",
      "Train Acc Q : 0.742906 \n",
      "Train Time: 67.115\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 7\n",
      "Train Acc Q : 0.743098 \n",
      "Train Time: 67.344\n",
      "Test Acc Q : 0.634615  \n",
      "Fixed Iteration: 8\n",
      "Train Acc Q : 0.790836 \n",
      "Train Time: 67.193\n",
      "Test Acc Q : 0.713141  \n",
      "Fixed Iteration: 9\n",
      "Train Acc Q : 0.850268 \n",
      "Train Time: 67.054\n",
      "Test Acc Q : 0.705128  \n",
      "Fixed Iteration: 10\n",
      "Train Acc Q : 0.883244 \n",
      "Train Time: 67.036\n",
      "Test Acc Q : 0.668269  \n",
      "Fixed Iteration: 11\n",
      "Train Acc Q : 0.900115 \n",
      "Train Time: 67.204\n",
      "Test Acc Q : 0.629808  \n",
      "Fixed Iteration: 12\n",
      "Train Acc Q : 0.910084 \n",
      "Train Time: 67.121\n",
      "Test Acc Q : 0.700321  \n",
      "Fixed Iteration: 13\n",
      "Train Acc Q : 0.918903 \n",
      "Train Time: 66.978\n",
      "Test Acc Q : 0.669872  \n",
      "Fixed Iteration: 14\n",
      "Train Acc Q : 0.927147 \n",
      "Train Time: 66.959\n",
      "Test Acc Q : 0.644231  \n",
      "Fixed Iteration: 15\n",
      "Train Acc Q : 0.937117 \n",
      "Train Time: 67.121\n",
      "Test Acc Q : 0.721154  \n",
      "Fixed Iteration: 16\n",
      "Train Acc Q : 0.945360 \n",
      "Train Time: 67.164\n",
      "Test Acc Q : 0.636218  \n",
      "Fixed Iteration: 17\n",
      "Train Acc Q : 0.953988 \n",
      "Train Time: 66.967\n",
      "Test Acc Q : 0.376603  \n",
      "Fixed Iteration: 18\n",
      "Train Acc Q : 0.953413 \n",
      "Train Time: 67.027\n",
      "Test Acc Q : 0.860577  \n",
      "Fixed Iteration: 19\n",
      "Train Acc Q : 0.960314 \n",
      "Train Time: 67.065\n",
      "Test Acc Q : 0.625000  \n",
      "Fixed Iteration: 20\n",
      "Train Acc Q : 0.961273 \n",
      "Train Time: 67.334\n",
      "Test Acc Q : 0.839744  \n",
      "Target Acc. 0.86 in 18 epochs at 1.12 min per epoch\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "\n",
    "fixed_acc = 0\n",
    "fixed_epochs = 0\n",
    "best_fixed_epoch = 0\n",
    "adaptive_acc = 0\n",
    "adaptive_epochs = 0\n",
    "\n",
    "fixed_time = []\n",
    "\n",
    "print(\"LR=0.01\")\n",
    "print(\"Establishing Fixed LR Best results\")\n",
    "\n",
    "for iter in range(max_epochs):\n",
    "    fixed_epochs +=1\n",
    "    print(\"Fixed Iteration:\", fixed_epochs)\n",
    "    start = time.time()\n",
    "    fixed_acc_train = train_fixed(model_1,train_dataloader,optimizer)\n",
    "    end = time.time()\n",
    "    print(\"Train Time: {:.3f}\".format(end-start))\n",
    "    fixed_time.append(end-start)\n",
    "    fixed_acc_test = test(model_1,test_dataloader)\n",
    "    if fixed_acc_test> fixed_acc and fixed_acc_train>fixed_acc:\n",
    "        fixed_acc = fixed_acc_test\n",
    "        best_fixed_epoch = fixed_epochs\n",
    "        \n",
    "print(\"Target Acc. {:.2f} in {} epochs at {:.2f} min per epoch\".format(\n",
    "        fixed_acc, best_fixed_epoch, np.mean(fixed_time)/60))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suHObVIYXRvI"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.manual_seed(756)\n",
    "model_1 = torchvision.models.resnet18(pretrained=False)\n",
    "model_1.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_features = model_1.fc.in_features\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "'''\n",
    "model_1.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256,9)\n",
    ")\n",
    "'''\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "\n",
    "lr_is = 1e-2\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = lr_is)\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "epsilon = 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "_Yz03i56x6FL",
    "outputId": "5ca4c067-0fbe-41e1-9b6f-22081bfa94e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Iteration: 1\n",
      "Train Acc Q : 0.769555 \n",
      "Train Time: 127.460\n",
      "Test Acc Q : 0.384615  \n",
      "Adaptive Iteration: 2\n",
      "Train Acc Q : 0.937692 \n",
      "Train Time: 127.715\n",
      "Test Acc Q : 0.650641  \n",
      "Adaptive Iteration: 3\n",
      "Train Acc Q : 0.948236 \n",
      "Train Time: 127.605\n",
      "Test Acc Q : 0.862179  \n",
      "\n",
      "Target Acc Reached\n",
      "Target Acc. 0.86 in 3 epochs at 127.59 sec per epoch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaptive_time = []\n",
    "adaptive_epochs = 0\n",
    "for iter in range(max_epochs):\n",
    "    adaptive_epochs +=1\n",
    "    print(\"Adaptive Iteration:\", adaptive_epochs)\n",
    "    start = time.time()\n",
    "    adaptive_acc_train = train_adaptive_lr(model_1,train_dataloader,optimizer)\n",
    "    end = time.time()\n",
    "    print(\"Train Time: {:.3f}\".format(end-start))\n",
    "    adaptive_time.append(end-start)\n",
    "    adaptive_acc_test = test(model_1,test_dataloader)\n",
    "    if adaptive_acc_test>fixed_acc and adaptive_acc_train>fixed_acc:\n",
    "        print()\n",
    "        print(\"Target Acc Reached\")\n",
    "        print(\"Target Acc. {:.2f} in {} epochs at {:.2f} sec per epoch\".format(\n",
    "        adaptive_acc_test, adaptive_epochs, np.mean(adaptive_time)))\n",
    "        break\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4drDXNtGfpO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XRay_LALR_Resnet18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
